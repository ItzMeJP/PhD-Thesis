

\chapter{Grasping Evaluation Proposal}
\label{cap3:grasping_eval}

After the grasping solution development, researchers encounter a common problem: how to evaluate the proposed methodology? The robotic grasping is typically composed of a complex system that includes, in most cases but not essential, the following issues: object sensing and identification; pose estimation; grasping detection; grasping selection; trajectory planning; force and stability estimation; collision avoidance, among others. All these components have their errors related and directly affect grasping performance. For instance, robotic manipulators and 3D sensors have intrinsic's action and measurement errors, respectively. Besides, estimation and planning algorithms also have considerable accuracy errors and variations.

Regarding this evaluation shortcoming, some authors proposed well-accepted assessments in the literature. These include point and rectangle grasping representation comparing with distance threshold and Jacquard index in \ac{DL} policies' database ground-truth. The Epsilon and Volume wrench space metrics are also other examples applied to analytical grasping methodologies (Section~\ref{cap2:related_work:sec:grasping_representation}). Although these metrics are focused on a specific grasping step (rectangle and point comparison metric in the detection, and Epsilon and Volume in physical active-pair interaction), they do not reflect the practical robot grasping performance. Some papers specify their own evaluation metric to a robotic grasping in a real scenario, but it is still difficult for readers to have a comparative review of the results. Therefore, these motivations allow us to formulate some fair and transparent definitions of the results' assessment. Thus, readers can have a clear idea of what is in the comparison between the methods. With the grasping problem steps presented in Figure~\ref{fig:eval}, it is defined four grasping evaluation success rate criteria: Grasp Prediction, Grasping Reaching, Grasping-Hold, and Handling Grasping.

\begin{figure}[h!] %because of cas-sc
\begin{tcolorbox}
% \centerline{\includegraphics[trim={7cm 8cm 7cm 9cm},clip,width=1\linewidth,angle=0]{Cap2/Figuras/friction_contact.pdf}}
\centerline{\includegraphics[trim={0cm 19.5cm 0cm 0.07cm},clip,width=1\linewidth,angle=0]{Cap2/Figuras/teste_2.pdf}}
\end{tcolorbox}
\caption{Proposed grasping assessments and their progression timeline. The categories evaluate the grasping performance in different levels based on the complexity of the actions, indicated by the arrows timeline. Each class englobes the prior class resulting in an ascending complexity order from Grasp Prediction (GPSR), Grasping Reaching (GRSR), Grasping-Hold (GHSR) to Handling Grasping success rates (HGSR). The last two successive images describe the 6DOF movements of HGSR.}
\label{fig:eval}
\end{figure}

\section{Grasping Prediction Success Rate}
\label{cap3:grasping_eval:sec:gpsr}

The \ac{GPSR} allows the grasp prediction (or detection) evaluation that consists of the grasp pose estimation generated by methodologies such as the \ac{DL} with \ac{CNN}~\cite{Mahler2019} and the \ac{SANN} optimization technique~\cite{AndrewT2004,carvalho2020}.

In these methods, single or multiple grasping poses are compared with ground-truth and an evaluation of how the graspable estimation is likely to perform, with success, given sensing type: RGB image, Depth map, or Point-Cloud. It is necessary to define if the object is previously known or, in case of \ac{SL} methodologies, if the metric considers sensing-wise (an object sensing data was already presented in the learning phase but with different perspectives from the test case) or object-wise (the object sensing data was never shown in the learning phase). The ground-truth used could be based on a labelled database, such as the \ac{CGD} database, or human supervision considering the user task expertise. Comparison metrics examples are the Euclidean distance between grasping points, the Jacquard threshold to rectangle grasping, the wrench space volume, or the $\epsilon$-value into a simulation procedure. These methods are discussed in Section~\ref{cap2:related_work:sec:grasping_representation}.

This class of success rate is prevalent in deep \ac{CNN} policy proposals, like~\cite{Redmon2015,Kumra2017,asif2018ensemblenet,song2020novel}.Usually, when applied in experimental cases, it has its success rate impaired since it does not evaluate the grasping interaction either the grasping related movements as can be seen in~\cite{Chu2018}.

The processing time related is \ac{GPT}. Normally in this step, the convergence time could be higher in analytical/optimization methods (Section~\ref{cap2:related_work:sec:grasping_approaches:subsec:analytical_review}) demanding a split in grasping planning: offline (\ac{Offline-GPT}) and run-time (\ac{Run-GPT}) approaches~\cite{carvalho2020}. In \ac{DL} policies it could require swap the processing unit from \ac{CPU} to \ac{GPU} generating the \ac{CPU-GPT} and \ac{GPU-GPT}, respectively.

The \ac{CPU-GPT} and \ac{GPU-GPT} could be directly compared; however, the unit processing explicitly shows the hardware requirement. In real applications, an ideally need is the \ac{CPU-GPT}  since \ac{CPU} is cheaper and simpler to be implemented and used, even though this achievement looks like far to state-of-art literature. It is important to note that, with the development of cheaper \acp{GPU} and accessible and straightforward libraries, like CUDA~\cite{cuda}, this could be an irrelevant issue.


\section{Grasping Reaching Success Rate} 
\label{cap3:grasping_eval:sec:grsr}

Suppose a grasping task where sensing is performed, followed by the grasp detection, grasp movement, and gripper's close over the grasp point. In this case, the \ac{GRSR} evaluates the methodology performance considering the deviation from the generate grasping pose and the active grasp point, i.e., the gripper's closing over the object. Therefore, it is a complete way to check the validity of error propagation in a practical scenario compared to \ac{GPSR}, which only evaluates mathematical modelling parameters where practical inconsistencies can appear. This metric includes the accuracy of object sensing, estimation, grasp prediction, grasping acting and can be specified by these error variations. Works like~\cite{moreira_2016} consider this intermediate error assessment, classified as valid or not by a kNN algorithm, critical to a reliable grasping since the \ac{GRSR} defines a starter error that can affect the next task steps.

However, not all physical interactions between the active-pair are evaluated, and only the grasping position precision and friction are appraised. It is important to note that small deviations could generate stable grasps, and a vast number of sensors, robotics manipulators, and grippers have a reduced intrinsic's error. Therefore in a controlled environment, the evaluated error could be small. Also, in referred conditions, the estimation, sensing, and planning algorithms must be designed with caution not to generate high error rates, i.e. a complete error propagation from \ac{GPSR} into \ac{GRSR}. This metric could be useful in precision grasping applications where the contact grasping region is necessary or the grasp slippage avoiding is critical. In addition, the \ac{GRSR} could be considered a filter to eliminate a significant pose grasping error and evaluate its propagation in the overall system.


\section{Grasping-Hold Success Rate} 
\label{cap3:grasping_eval:sec:ghsr}

The \ac{GHSR} allows a complete grasping evaluation criteria. It is considered a robotic grasping application where sensing is performed followed by grasp detection, grasp movement, gripper close over the grasp point, lift the object and hold it for a period. Besides evaluating the error propagation in a practical scenario, as \ac{GRSR} does, it is possible to check the equilibrium of the grasping performance over perturbations and physical interactions, e.g., the slip, wrench space configuration, and the gravity force actuation. This metric could also be evaluated according to object and gripper material friction changes and holding time variation. It important to note that this category excludes the unintentionally grasp that could happen in cluttered and/or bin-picking grasping operations.

\section{Handling Grasping Success Rate}
\label{cap3:grasping_eval:sec:hgsr}

Although \ac{GHSR} could be enough to define a good grasping approach, a more realistic grasping evaluation criteria is the \ac{HGSR}.  Besides including all considerations of \ac{GHSR},  the \ac{HGSR} evaluates the grasping holding of an object and moving it in all robot's DOFs, checking its stability. This metric is relevant for practical scenarios since, in the industry, the work cycle is an important parameter to evaluate. The \ac{GHSR} could be assessed according to the robot movement's speed and acceleration variation, besides the work cycle. It is also possible to include the object's placing movement. However, any analysis of this procedure could confront a new task apart from grasping.

\section{Discussion}
\label{cap3:grasping_eval:sec:discussion}

Aiming to deploy the proposed grasping evaluation in currently state-of-art and, stabilising a fair comparison about the literature solutions, Table~\ref{tab:met_state_of_art} presents some grasping approaches and their performance. This table is a guiding tool, and the readers are encouraged to check the source since, besides the specific restriction used in each paper's database that can lead to an unfair comparison, the results presented here are an elucidation give the described conditions: 

\begin{enumerate_jp}
    \item All assessments are restricted to agnostic-grasping (the current challenge in grasping) even though some paper also present better results evaluation with previous knowledge of object shape; 
    \item Only object-wise metric are presented since the object-agnostic is considered;
    \item For tests where the author categorise the objects, the most ``typical'' class is selected in the present table;
    \item The column ``Model Interaction'' indicates if any model interaction is needed to synthesised or selected a grasp (it does not include the database build step of results evaluation) since this affects the grasping performance convergence time;
    \item It is only considered static scenario;
    \item Each methodology was classified according to proposed Grasp Evaluation, Section~\ref{cap3:grasping_eval}. Therefore, if realised, it is presented the most complex category in descending order of: \ac{HGSR}, \ac{GHSR}, \ac{GRSR} and \ac{GPSR}. 
\end{enumerate_jp}


%clutter and isolated scenarios are specified

%\input{Cap2/table}

\clearpage
\thispagestyle{empty}
\input{Cap2/table}
\clearpage

Based on Table~\ref{tab:met_state_of_art} and the grasping evaluation discussed in the presented chapter, it is possible to infer that, even with interesting proposals and results successfully deployed in specific use cases, the robotic grasping still does not have a feasible generalisation solution that comprises the modern industry demands of fast design and easy deployment.

Since a complete and generic solution is unreachable until now, there exists a lack in the deployment of a modular and flexible grasping framework for robots attending to real industry demands and a well structured and formalised architecture which organizes approaches allowing the evaluation and the base to new advancements in science. The evaluation metrics discussed in this chapter could be the first step to achieving this proposal and formalising the research process.